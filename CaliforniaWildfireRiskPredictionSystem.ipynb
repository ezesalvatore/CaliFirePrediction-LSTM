{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyO0bDJzEUXvTCSvQ0L4Bj9U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezesalvatore/CaliFirePrediction-LSTM/blob/main/CaliforniaWildfireRiskPredictionSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# California Wildfire Risk Prediction System\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "25LzU1YfcKTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Overview**\n",
        "  This machine learning project LSTM models with full-stack web development to create an wildfire prediction system for California.\n"
      ],
      "metadata": {
        "id": "VPqT-IDbCsDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Motivations**\n",
        "In recent years, California has experience massive wildfire seasons, with climate change only increasing the frequency and destructiveness of these fires. My mission is to prevent wildfires by predicting if they will happen. The prediction will give communities, firefighters, and other emergency services a head start."
      ],
      "metadata": {
        "id": "zX1j9IKJrTXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tech Stack**\n",
        "\n",
        "* **Datasets** of historical fire data\n",
        "* **LSTM models** built with TensorFlow/Keras trained in google collab\n",
        "* **Django** backends uses trained models with real-time API data\n",
        "* **React** displays interactive map interface with warnings"
      ],
      "metadata": {
        "id": "lp6Mk1n9rHtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Documentation**\n",
        "\n",
        "This documents information about the California Wildfire Risk Prediction System dataset being used. This inculdes its source, date range, variables, limitations, and citation information.\n"
      ],
      "metadata": {
        "id": "YNAQhNW7rW2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CAL FIRE Historic Wildland Fire Perimeters Dataset Documentation\n",
        "**Date Range** 1878- Present (Oldest and Cohesive on Cal Fire documentation <br>\n",
        "**Data Source** [California Department of Forestry and Fire Protection's Fire and Resource Assessment Program (FRAP)](https://www.fire.ca.gov/what-we-do/fire-resource-assessment-program/fire-perimeters)\n",
        "###**Limiation of Dataset**\n",
        "This is the most complete dataset for califorina history, but there are 483 fires that are totally missing from the CAL FIRE Redbook \"Large, Damaging Fires\"\n",
        "###**Data Collection of dataset**\n",
        "CAL Fire document fires that are: <br> >= 10 acres in timber <br> >= 50 acres in brush <br> >= 300 acres in grass <br>  >= 1 fatality <br> >= 3 residential building burned\n",
        "###**Variables used:**\n",
        "`ALARM_DATE`= Fire start date <br>\n",
        "`geometry` = Fire perimeter coordinates <br>\n",
        "`GIS_ACRES` = Fire size in acres\n",
        "###**Variables from Code**\n",
        "`fire_occurred` = Binary target variable (0 = no fire, 1 = fire happened)<br>\n",
        "`fire_size_acres` = Filtered fire size (>= 10 acres only)<br>\n"
      ],
      "metadata": {
        "id": "77hZvU96Qc36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NOAA National Centers for Environmental Information Dataset Documentation**<br>\n",
        "**Date Range:** January 1, 2009 - December 31, 2013 <br>\n",
        "**Data Source:** [NOAA GHCN-Daily dataset](https://www.ncei.noaa.gov/cdo-web/search?datasetid=GHCND)\n",
        "###**Station Location:**\n",
        "Arcata Eureka Airport `USW00024283` <br>\n",
        "Redding Airport `USW00024257` <br> Marysville Airport `USW00093205`<br>\n",
        "Napa Airport `USW00093227`  <br> Santa Maria Airport `USW00023273`  <br> Watsonville Airport `USW00023277` <br> Stockton Airport `USW00023237` <br>\n",
        "Merced Municipal Airport `USW00023257`<br> Fresno Yosemite International `USW00093193` <br> Bakersfield Airport `USW00023155`  <br>\n",
        " Santa Barbara 11W `USW00023190`<br>  Burbank-Glendale-Pasadena Airport `USW00023152` <br> Oceanside Airport `USW00053121`\n",
        "\n",
        "###**Variables Collected from Dataset:**\n",
        "`PRCP` = Precipitation (mm) <br>\n",
        "`TMAX`= Max Temp (°C) <br>\n",
        "`TMIN` = Min Temp (°C) <br>\n",
        "`AWND` = Average Wind Speed (m/s)\n",
        "\n",
        "###**Variables from Code**\n",
        "`temperature_range` = TMAX-TMIN <br>\n",
        "`days_since_rain` = Days with PRCP < 0.25 <br>\n",
        "`fire_season` = May - October period <br>\n",
        "`station_id` = Weather station <br>\n",
        "\n",
        "\n",
        "###**Citation**\n",
        "National Centers for Environmental Information, NOAA.(2025)\n"
      ],
      "metadata": {
        "id": "bneZLYKtH_8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Modis NDVI Dataset**\n",
        "**Date Range:** 2000-Present <br>\n",
        "**Data Source:** [Google Earth Engine - MODIS/061/MOD13Q1](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD13Q1)\n",
        "\n",
        "###**Regional Coverage**\n",
        "Since Califorina is made up with different regions with vastly differnt climate I separated the region my polygons will collect the data\n",
        "\n",
        "###**Data Collection Method**\n",
        "```python\n",
        "modis_ndvi = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
        "    .select('NDVI') \\\n",
        "    .filterDate('2009-01-01', '2013-12-31')\n",
        "```\n",
        "\n",
        "###**Variables from Dataset**\n",
        "`NDVI`= Raw MODIS NDVI band values (range: -1 to +1)\n",
        "\n",
        "###**Variables from Code**\n",
        "`ndvi_mean` = average NDVI for each fire region <br>\n",
        "`ndvi_stdev` = measure of NDVI variation<br>\n",
        "`region` = fire zone\n",
        "\n",
        "###**Citation**\n",
        "LP DAAC. (2021). MOD13Q1 MODIS/Terra Vegetation Indices 16-Day L3 Global 250m V061. NASA EOSDIS Land Processes DAAC."
      ],
      "metadata": {
        "id": "J2nwORqrNmZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Dataset Creation**"
      ],
      "metadata": {
        "id": "Fgs4BJeKqoBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/fire_prediction_project'\n",
        "folders = [\n",
        "    'raw_data/fires_calfire',\n",
        "    'raw_data/weather_ghcn',\n",
        "    'raw_data/vegetation_modis',\n",
        "]\n",
        "\n",
        "for folder in folders:\n",
        "    full_path = f'{base_path}/{folder}'\n",
        "    os.makedirs(full_path, exist_ok=True)\n",
        "    print(f\"Created: {folder}\")"
      ],
      "metadata": {
        "id": "AM4HmM5yq5Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if data exists\n",
        "\n",
        "print(os.listdir('/content/drive/MyDrive/fire_prediction_project/raw_data/fires_calfire'))\n",
        "print(os.listdir('/content/drive/MyDrive/fire_prediction_project/raw_data/weather_ghcn'))\n",
        "print(os.listdir('/content/drive/MyDrive/fire_prediction_project/raw_data/vegetation_modis'))\n"
      ],
      "metadata": {
        "id": "iWd5cZ7et4w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fire Perimeters Loading, Cleaning, Visulization data retrieved**"
      ],
      "metadata": {
        "id": "rEJzgBdEecnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "\n",
        "def load_fire_data():\n",
        "    \"\"\"\n",
        "    Loads CAL FIRE data and creates LSTM targets directly.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two pandas DataFrames:\n",
        "            - study_fires (pd.DataFrame or None): DataFrame of filtered fire incidents within the study period, or None if loading fails.\n",
        "            - daily_targets (pd.DataFrame or None): DataFrame of daily fire occurrence targets for LSTM, or None if loading fails.\n",
        "    \"\"\"\n",
        "    fire_folder = '/content/drive/MyDrive/fire_prediction_project/raw_data/fires_calfire'\n",
        "    print(f\"Looking for fire data in: {fire_folder}\")\n",
        "\n",
        "    if not os.path.exists(fire_folder):\n",
        "        print(\"Error: Fire folder not found!\")\n",
        "        return None, None\n",
        "\n",
        "    shp_files = [f for f in os.listdir(fire_folder) if f.endswith('.shp')]\n",
        "    if not shp_files:\n",
        "        print(\"Note: No fire shapefiles found.\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"Found {len(shp_files)} shapefile(s)\")\n",
        "    first_shp_file = f'{fire_folder}/{shp_files[0]}'\n",
        "\n",
        "    try:\n",
        "        fire_gdf = gpd.read_file(first_shp_file)\n",
        "        print(f\"Loaded {len(fire_gdf)} fire records\")\n",
        "        return process_fire_data(fire_gdf)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading shapefile: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def process_fire_data(fire_gdf):\n",
        "    \"\"\"\n",
        "    Process fire data and create LSTM targets.\n",
        "\n",
        "    Args:\n",
        "        fire_gdf (gpd.GeoDataFrame): GeoDataFrame containing the raw fire data.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two pandas DataFrames:\n",
        "            - study_fires (pd.DataFrame): DataFrame of processed and filtered fire incidents.\n",
        "            - daily_targets (pd.DataFrame): DataFrame of daily fire occurrence targets for LSTM.\n",
        "    \"\"\"\n",
        "    print(\"Processing fire data...\")\n",
        "\n",
        "    # Convert to WGS84 which is a common lat/longitude system\n",
        "    if fire_gdf.crs != 'EPSG:4326':\n",
        "        fire_gdf = fire_gdf.to_crs('EPSG:4326')\n",
        "\n",
        "    # Drop the geometry to get the center of the fire perimeter\n",
        "    fire_df = pd.DataFrame(fire_gdf.drop(columns='geometry'))\n",
        "\n",
        "    # Get the center of fire geometry\n",
        "    centroids = fire_gdf.geometry.centroid\n",
        "    fire_df['centroid_lat'] = centroids.y\n",
        "    fire_df['centroid_lon'] = centroids.x\n",
        "\n",
        "    # Updated comprehensive weather station coordinates\n",
        "    weather_stations = [\n",
        "        {'name': 'Arcata Eureka Airport', 'usw_id': 'USW00024283', 'lat': 40.97844, 'lon': -124.10479},\n",
        "        {'name': 'Redding Airport', 'usw_id': 'USW00024257', 'lat': 40.51, 'lon': -122.29},\n",
        "        {'name': 'Marysville Airport (Beale AFB)', 'usw_id': 'USW00093205', 'lat': 39.136089, 'lon': -121.436567},\n",
        "        {'name': 'Napa Airport', 'usw_id': 'USW00093227', 'lat': 38.213194, 'lon': -122.280694},\n",
        "        {'name': 'Stockton Airport', 'usw_id': 'USW00023237', 'lat': 37.88997, 'lon': -121.22637},\n",
        "        {'name': 'Fresno Yosemite International', 'usw_id': 'USW00093193', 'lat': 36.77999, 'lon': -119.72016},\n",
        "        {'name': 'Santa Maria Airport', 'usw_id': 'USW00023273', 'lat': 34.8927, 'lon': -120.4545},\n",
        "        {'name': 'Watsonville Airport', 'usw_id': 'USW00023277', 'lat': 36.935, 'lon': -121.79},\n",
        "        {'name': 'Merced Municipal Airport', 'usw_id': 'USW00023257', 'lat': 37.28470, 'lon': -120.51400},\n",
        "        {'name': 'Bakersfield Airport', 'usw_id': 'USW00023155', 'lat': 35.3217, 'lon': -118.9910},\n",
        "        {'name': 'Santa Barbara 11W', 'usw_id': 'USW00023190', 'lat': 34.4208, 'lon': -119.6982},\n",
        "        {'name': 'Burbank-Glendale-Pasadena Airport', 'usw_id': 'USW00023152', 'lat': 34.2003, 'lon': -118.3552},\n",
        "        {'name': 'Oceanside Airport', 'usw_id': 'USW00023181', 'lat': 33.218, 'lon': -117.351}\n",
        "    ]\n",
        "\n",
        "    def find_nearest_weather_station(lat, lon):\n",
        "        \"\"\"\n",
        "        Find the nearest weather station to given coordinates.\n",
        "\n",
        "        Args:\n",
        "            lat (float): Latitude coordinate of the fire\n",
        "            lon (float): Longitude coordinate of the fire\n",
        "\n",
        "        Returns:\n",
        "            str: USW ID of the nearest weather station\n",
        "        \"\"\"\n",
        "        if pd.isna(lat) or pd.isna(lon):\n",
        "            return 'Unknown'\n",
        "\n",
        "        # Check if within California bounds (rough bounds)\n",
        "        if not (32.4 <= lat <= 42.2 and -124.6 <= lon <= -114.0):\n",
        "            return 'Unknown'\n",
        "\n",
        "        min_distance = float('inf')\n",
        "        nearest_station = 'Unknown'\n",
        "\n",
        "        for station in weather_stations:\n",
        "            # Calculate Euclidean distance (approximate since we're dealing with small distances)\n",
        "            distance = np.sqrt((lat - station['lat'])**2 + (lon - station['lon'])**2)\n",
        "\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                nearest_station = station['usw_id']\n",
        "\n",
        "        return nearest_station\n",
        "\n",
        "    # Assign each fire to its nearest weather station\n",
        "    fire_df['weather_station'] = fire_df.apply(\n",
        "        lambda row: find_nearest_weather_station(row['centroid_lat'], row['centroid_lon']),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Renaming columns to match expected format\n",
        "    column_mapping = {\n",
        "        'ALARM_DATE': 'fire_date',\n",
        "        'GIS_ACRES': 'fire_size_acres',\n",
        "        'YEAR_': 'year'\n",
        "    }\n",
        "    for old_name, new_name in column_mapping.items():\n",
        "        if old_name in fire_df.columns:\n",
        "            fire_df = fire_df.rename(columns={old_name: new_name})\n",
        "\n",
        "    # Process dates and filter\n",
        "    if 'fire_date' not in fire_df.columns:\n",
        "        print(\"Warning: 'fire_date' column not found.\")\n",
        "        return None, None\n",
        "\n",
        "    fire_df['fire_date'] = pd.to_datetime(fire_df['fire_date'], errors='coerce')\n",
        "    fire_df = fire_df.dropna(subset=['fire_date'])\n",
        "\n",
        "    # Filter to study period and significant fires\n",
        "    study_fires = fire_df[\n",
        "        (fire_df['fire_date'] >= '2009-01-01') &\n",
        "        (fire_df['fire_date'] <= '2013-12-31')\n",
        "    ].copy()\n",
        "\n",
        "    if 'fire_size_acres' in study_fires.columns:\n",
        "        study_fires = study_fires[study_fires['fire_size_acres'] >= 10]\n",
        "\n",
        "    print(f\"Study period fires: {len(study_fires)} (2009-2013)\")\n",
        "\n",
        "    # Print distribution by weather station\n",
        "    print(\"\\nFire distribution by weather station:\")\n",
        "    station_counts = study_fires['weather_station'].value_counts()\n",
        "    for station_id, count in station_counts.items():\n",
        "        station_name = next((s['name'] for s in weather_stations if s['usw_id'] == station_id), station_id)\n",
        "        print(f\"  {station_name} ({station_id}): {count} fires\")\n",
        "\n",
        "    # Create LSTM targets\n",
        "    daily_targets = create_daily_fire_targets(study_fires)\n",
        "\n",
        "    return study_fires, daily_targets\n",
        "\n",
        "def create_daily_fire_targets(fire_df):\n",
        "    \"\"\"\n",
        "    Creates 5-day fire prediction targets for LSTM training.\n",
        "\n",
        "    Args:\n",
        "        fire_df (pd.DataFrame): DataFrame of fire incidents with 'fire_date' and 'weather_station' columns.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with daily 5-day fire prediction targets.\n",
        "    \"\"\"\n",
        "    print(\"Creating 5-day fire prediction targets...\")\n",
        "\n",
        "    if 'fire_date' not in fire_df.columns or 'weather_station' not in fire_df.columns:\n",
        "        print(\"Warning: Missing required columns for targets.\")\n",
        "        return None\n",
        "\n",
        "    # Create date range - end 5 days early to allow for 5-day prediction window\n",
        "    date_range = pd.date_range('2009-01-01', '2013-12-26', freq='D')  # Dec 26 instead of Dec 31\n",
        "    stations = fire_df['weather_station'].unique()\n",
        "    stations = [s for s in stations if s != 'Unknown']\n",
        "\n",
        "    # Build daily targets\n",
        "    daily_targets = []\n",
        "    for date in date_range:\n",
        "        for station in stations:\n",
        "            # Look for fires in the next 5 days (tomorrow through day 5)\n",
        "            window_start = date + pd.Timedelta(days=1)\n",
        "            window_end = date + pd.Timedelta(days=5)\n",
        "\n",
        "            fires_in_window = fire_df[\n",
        "                (fire_df['fire_date'] >= window_start) &\n",
        "                (fire_df['fire_date'] <= window_end) &\n",
        "                (fire_df['weather_station'] == station)\n",
        "            ]\n",
        "\n",
        "            daily_targets.append({\n",
        "                'date': date,\n",
        "                'weather_station': station,\n",
        "                'fire_within_5_days': 1 if len(fires_in_window) > 0 else 0\n",
        "            })\n",
        "\n",
        "    targets_df = pd.DataFrame(daily_targets)\n",
        "\n",
        "    # Print statistics\n",
        "    positive_rate = targets_df['fire_within_5_days'].mean() * 100\n",
        "    print(f\"Created {len(targets_df)} daily target records\")\n",
        "    print(f\"5-day fire prediction rate: {positive_rate:.1f}%\")\n",
        "\n",
        "    return targets_df\n",
        "\n",
        "# Load and process fire data\n",
        "print(\"Loading fire data with updated weather stations...\")\n",
        "fire_data, fire_targets = load_fire_data()\n",
        "\n",
        "print(f\"\\nFire data shape: {fire_data.shape if fire_data is not None else 'None'}\")\n",
        "print(f\"LSTM targets shape: {fire_targets.shape if fire_targets is not None else 'None'}\")"
      ],
      "metadata": {
        "id": "cLzqSazDekyD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def visualize_fire_data(fire_data, fire_targets):\n",
        "    \"\"\"Simple fire data visualizations\"\"\"\n",
        "\n",
        "    # Set up the plot style\n",
        "    plt.style.use('default')\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('🔥 California Fire Data Overview (2009-2013)', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Fires by Weather Station\n",
        "    station_counts = fire_data['weather_station'].value_counts()\n",
        "    axes[0,0].bar(range(len(station_counts)), station_counts.values, color='orangered', alpha=0.7)\n",
        "    axes[0,0].set_title('Total Fires by Region')\n",
        "    axes[0,0].set_ylabel('Number of Fires')\n",
        "    axes[0,0].set_xlabel('Weather Stations')\n",
        "    axes[0,0].set_xticks(range(len(station_counts)))\n",
        "    axes[0,0].set_xticklabels([s[-6:] for s in station_counts.index], rotation=45)  # Show last 6 chars of station ID\n",
        "\n",
        "    # 2. Fire Size Distribution\n",
        "    axes[0,1].hist(fire_data['fire_size_acres'], bins=30, color='red', alpha=0.6, edgecolor='black')\n",
        "    axes[0,1].set_title('Fire Size Distribution')\n",
        "    axes[0,1].set_xlabel('Fire Size (acres)')\n",
        "    axes[0,1].set_ylabel('Number of Fires')\n",
        "    axes[0,1].set_yscale('log')  # Log scale because of wide range\n",
        "\n",
        "    # 3. Monthly Fire Pattern\n",
        "    fire_data['month'] = fire_data['fire_date'].dt.month\n",
        "    monthly_fires = fire_data['month'].value_counts().sort_index()\n",
        "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "\n",
        "    axes[1,0].plot(monthly_fires.index, monthly_fires.values, 'o-',\n",
        "                   linewidth=3, markersize=8, color='darkred')\n",
        "    axes[1,0].set_title('Fires by Month')\n",
        "    axes[1,0].set_xlabel('Month')\n",
        "    axes[1,0].set_ylabel('Number of Fires')\n",
        "    axes[1,0].set_xticks(range(1, 13))\n",
        "    axes[1,0].set_xticklabels(months, rotation=45)\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. Fire Risk Rate by Station\n",
        "    if 'fire_within_5_days' in fire_targets.columns:\n",
        "        risk_by_station = fire_targets.groupby('weather_station')['fire_within_5_days'].mean() * 100\n",
        "    else:\n",
        "        # Fallback if column name is different\n",
        "        risk_by_station = fire_targets.groupby('weather_station').iloc[:,2].mean() * 100\n",
        "\n",
        "    axes[1,1].bar(range(len(risk_by_station)), risk_by_station.values,\n",
        "                  color='orange', alpha=0.7)\n",
        "    axes[1,1].set_title('5-Day Fire Risk by Region')\n",
        "    axes[1,1].set_ylabel('Fire Risk (%)')\n",
        "    axes[1,1].set_xlabel('Weather Stations')\n",
        "    axes[1,1].set_xticks(range(len(risk_by_station)))\n",
        "    axes[1,1].set_xticklabels([s[-6:] for s in risk_by_station.index], rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print Summary Statistics\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"🔥 FIRE DATA SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"📊 Total Fires: {len(fire_data):,}\")\n",
        "    print(f\"📅 Date Range: {fire_data['fire_date'].min().strftime('%Y-%m-%d')} to {fire_data['fire_date'].max().strftime('%Y-%m-%d')}\")\n",
        "    print(f\"🌡️ Weather Stations: {fire_data['weather_station'].nunique()}\")\n",
        "    print(f\"🔢 Average Fire Size: {fire_data['fire_size_acres'].mean():.0f} acres\")\n",
        "    print(f\"📈 Largest Fire: {fire_data['fire_size_acres'].max():,.0f} acres\")\n",
        "\n",
        "    # Fire season analysis\n",
        "    fire_season_fires = fire_data[fire_data['fire_date'].dt.month.isin([5,6,7,8,9,10])]\n",
        "    fire_season_pct = (len(fire_season_fires) / len(fire_data)) * 100\n",
        "    print(f\"🌡️ Fire Season (May-Oct): {fire_season_pct:.1f}% of all fires\")\n",
        "\n",
        "    # LSTM targets summary\n",
        "    if fire_targets is not None:\n",
        "        total_days = len(fire_targets)\n",
        "        fire_days = fire_targets.iloc[:,2].sum() if fire_targets.shape[1] > 2 else 0\n",
        "        overall_risk = (fire_days / total_days) * 100 if total_days > 0 else 0\n",
        "        print(f\"🎯 Overall 5-Day Fire Risk: {overall_risk:.1f}%\")\n",
        "        print(f\"📋 LSTM Training Records: {total_days:,}\")\n",
        "\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# Simple usage example:\n",
        "visualize_fire_data(fire_data, fire_targets)"
      ],
      "metadata": {
        "id": "7DsU1YzXBfVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NOAA load, clean, visulization, and retrival**"
      ],
      "metadata": {
        "id": "SfzFnwjFVeBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_weather_data():\n",
        "    \"\"\"\n",
        "    Load and process weather data from NOAA GHCN-Daily dataset for fire prediction.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Processed weather data with engineered features, or None if loading fails.\n",
        "    \"\"\"\n",
        "    weather_path = '/content/drive/MyDrive/fire_prediction_project/raw_data/weather_ghcn/4030855.csv'\n",
        "\n",
        "    print(f\"Loading weather data from: {weather_path}\")\n",
        "\n",
        "    if not os.path.exists(weather_path):\n",
        "        print(\"Error: Weather file not found!\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Load the weather data\n",
        "        weather_df = pd.read_csv(weather_path)\n",
        "        print(f\"Loaded {len(weather_df)} weather records\")\n",
        "\n",
        "        # Process the weather data\n",
        "        processed_weather = process_weather_data(weather_df)\n",
        "\n",
        "        return processed_weather\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading weather data: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_weather_data(weather_df):\n",
        "    \"\"\"\n",
        "    Process raw weather data and create engineered features.\n",
        "\n",
        "    Args:\n",
        "        weather_df (pd.DataFrame): Raw weather data from NOAA\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Processed weather data with engineered features\n",
        "    \"\"\"\n",
        "    print(\"Processing weather data...\")\n",
        "\n",
        "    # Convert date column\n",
        "    weather_df['DATE'] = pd.to_datetime(weather_df['DATE'])\n",
        "\n",
        "    # Filter to study period\n",
        "    weather_df = weather_df[\n",
        "        (weather_df['DATE'] >= '2009-01-01') &\n",
        "        (weather_df['DATE'] <= '2013-12-31')\n",
        "    ].copy()\n",
        "\n",
        "    # Rename columns for consistency\n",
        "    weather_df = weather_df.rename(columns={\n",
        "        'DATE': 'date',\n",
        "        'STATION': 'weather_station'\n",
        "    })\n",
        "\n",
        "    # Convert temperature from tenths of degrees C to degrees C\n",
        "    if 'TMAX' in weather_df.columns:\n",
        "        weather_df['TMAX'] = weather_df['TMAX'] / 10.0\n",
        "    if 'TMIN' in weather_df.columns:\n",
        "        weather_df['TMIN'] = weather_df['TMIN'] / 10.0\n",
        "\n",
        "    # Convert precipitation from tenths of mm to mm\n",
        "    if 'PRCP' in weather_df.columns:\n",
        "        weather_df['PRCP'] = weather_df['PRCP'] / 10.0\n",
        "\n",
        "    # Convert wind speed from tenths of m/s to m/s\n",
        "    if 'AWND' in weather_df.columns:\n",
        "        weather_df['AWND'] = weather_df['AWND'] / 10.0\n",
        "\n",
        "    # Create engineered features\n",
        "    weather_df = create_weather_features(weather_df)\n",
        "\n",
        "    print(f\"Processed weather data: {len(weather_df)} records\")\n",
        "    print(f\"Date range: {weather_df['date'].min().date()} to {weather_df['date'].max().date()}\")\n",
        "    print(f\"Weather stations: {weather_df['weather_station'].nunique()}\")\n",
        "\n",
        "    return weather_df\n",
        "\n",
        "def create_weather_features(weather_df):\n",
        "    \"\"\"\n",
        "    Create engineered weather features for fire prediction.\n",
        "\n",
        "    Args:\n",
        "        weather_df (pd.DataFrame): Basic weather data\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Weather data with engineered features\n",
        "    \"\"\"\n",
        "    print(\"Creating weather features...\")\n",
        "\n",
        "    # Temperature range\n",
        "    if 'TMAX' in weather_df.columns and 'TMIN' in weather_df.columns:\n",
        "        weather_df['temperature_range'] = weather_df['TMAX'] - weather_df['TMIN']\n",
        "\n",
        "    # Fire season indicator (May - October)\n",
        "    weather_df['fire_season'] = weather_df['date'].dt.month.isin([5, 6, 7, 8, 9, 10]).astype(int)\n",
        "\n",
        "    # Add wind strength features\n",
        "    weather_df = add_wind_strength(weather_df)\n",
        "\n",
        "    # Days since rain (calculated per weather station)\n",
        "    weather_df = weather_df.sort_values(['weather_station', 'date'])\n",
        "\n",
        "    def calculate_days_since_rain(group):\n",
        "        \"\"\"Calculate days since last significant rain (>= 0.25mm) for each station\"\"\"\n",
        "        group = group.copy()\n",
        "        group['days_since_rain'] = 0\n",
        "\n",
        "        if 'PRCP' in group.columns:\n",
        "            last_rain_day = 0\n",
        "            for i, row in group.iterrows():\n",
        "                if pd.notna(row['PRCP']) and row['PRCP'] >= 0.25:\n",
        "                    last_rain_day = 0\n",
        "                else:\n",
        "                    last_rain_day += 1\n",
        "                group.loc[i, 'days_since_rain'] = last_rain_day\n",
        "\n",
        "        return group\n",
        "\n",
        "    # Apply days since rain calculation by weather station\n",
        "    weather_df = weather_df.groupby('weather_station').apply(calculate_days_since_rain).reset_index(drop=True)\n",
        "\n",
        "    # Fill missing values\n",
        "    weather_df['PRCP'] = weather_df['PRCP'].fillna(0)\n",
        "    weather_df['AWND'] = weather_df['AWND'].fillna(weather_df['AWND'].mean())\n",
        "\n",
        "    # Select final columns\n",
        "    feature_columns = [\n",
        "        'date', 'weather_station', 'PRCP', 'TMAX', 'TMIN', 'AWND',\n",
        "        'temperature_range', 'days_since_rain', 'fire_season',\n",
        "        'wind_mph', 'wind_strength'\n",
        "    ]\n",
        "\n",
        "    # Only keep columns that exist\n",
        "    available_columns = [col for col in feature_columns if col in weather_df.columns]\n",
        "    weather_df = weather_df[available_columns]\n",
        "\n",
        "    print(f\"Weather features created: {list(weather_df.columns)}\")\n",
        "\n",
        "    # Print basic statistics\n",
        "    print(\"\\nWeather data summary:\")\n",
        "    print(f\"  Average TMAX: {weather_df['TMAX'].mean():.1f}°C\")\n",
        "    print(f\"  Average TMIN: {weather_df['TMIN'].mean():.1f}°C\")\n",
        "    print(f\"  Average PRCP: {weather_df['PRCP'].mean():.1f}mm\")\n",
        "    print(f\"  Average wind: {weather_df['wind_mph'].mean():.1f} mph\")\n",
        "    print(f\"  Fire season days: {weather_df['fire_season'].sum()}\")\n",
        "    print(f\"  Max days since rain: {weather_df['days_since_rain'].max()}\")\n",
        "\n",
        "    # Wind strength summary\n",
        "    print(f\"\\n🌪️ Wind strength summary:\")\n",
        "    print(weather_df['wind_strength'].value_counts())\n",
        "\n",
        "    return weather_df\n",
        "\n",
        "def add_wind_strength(weather_df):\n",
        "    \"\"\"\n",
        "    Add simple wind strength categories for fire danger.\n",
        "\n",
        "    Args:\n",
        "        weather_df: Weather dataframe with 'AWND' column\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with wind strength features added\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert wind speed to mph (AWND is in m/s)\n",
        "    weather_df['wind_mph'] = weather_df['AWND'] * 2.237\n",
        "\n",
        "    # Simple wind strength categories\n",
        "    def get_wind_strength(wind_mph):\n",
        "        if wind_mph >= 25:\n",
        "            return 'EXTREME'      # Santa Ana/Diablo conditions\n",
        "        elif wind_mph >= 15:\n",
        "            return 'HIGH'         # Fire danger threshold\n",
        "        elif wind_mph >= 8:\n",
        "            return 'MODERATE'     # Elevated risk\n",
        "        else:\n",
        "            return 'LOW'          # Normal conditions\n",
        "\n",
        "    weather_df['wind_strength'] = weather_df['wind_mph'].apply(get_wind_strength)\n",
        "\n",
        "    return weather_df\n",
        "\n",
        "# Load weather data\n",
        "print(\"Loading weather data...\")\n",
        "weather_data = load_weather_data()\n",
        "\n",
        "if weather_data is not None:\n",
        "    print(f\"\\nWeather data shape: {weather_data.shape}\")\n",
        "    print(\"\\nSample weather data:\")\n",
        "    print(weather_data.head())\n",
        "else:\n",
        "    print(\"Failed to load weather data.\")"
      ],
      "metadata": {
        "id": "SYIu4uVMVzNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Google Earth Engine Code for NDVI Data Retrieval**"
      ],
      "metadata": {
        "id": "qCN1M2N-IvCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "# Initialize GEE\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='fire-prediction-ee-salvatore')\n",
        "\n",
        "# Define California state boundary for intersection\n",
        "california = ee.FeatureCollection(\"TIGER/2018/States\") \\\n",
        "    .filter(ee.Filter.eq('STUSPS', 'CA')) \\\n",
        "    .geometry()\n",
        "\n",
        "# Updated comprehensive weather station locations\n",
        "weather_stations = [\n",
        "    {'name': 'Arcata Eureka Airport', 'usw': 'USW00024283', 'lat': 40.97844, 'lon': -124.10479},\n",
        "    {'name': 'Redding Airport', 'usw': 'USW00024257', 'lat': 40.51, 'lon': -122.29},\n",
        "    {'name': 'Marysville Airport (Beale AFB)', 'usw': 'USW00093205', 'lat': 39.136089, 'lon': -121.436567},\n",
        "    {'name': 'Napa Airport', 'usw': 'USW00093227', 'lat': 38.213194, 'lon': -122.280694},\n",
        "    {'name': 'Stockton Airport', 'usw': 'USW00023237', 'lat': 37.88997, 'lon': -121.22637},\n",
        "    {'name': 'Fresno Yosemite International', 'usw': 'USW00093193', 'lat': 36.77999, 'lon': -119.72016},\n",
        "    {'name': 'Santa Maria Airport', 'usw': 'USW00023273', 'lat': 34.8927, 'lon': -120.4545},\n",
        "    {'name': 'Watsonville Airport', 'usw': 'USW00023277', 'lat': 36.935, 'lon': -121.79},\n",
        "    {'name': 'Merced Municipal Airport', 'usw': 'USW00023257', 'lat': 37.28470, 'lon': -120.51400},\n",
        "    {'name': 'Bakersfield Airport', 'usw': 'USW00023155', 'lat': 35.3217, 'lon': -118.9910},\n",
        "    {'name': 'Santa Barbara 11W', 'usw': 'USW00023190', 'lat': 34.4208, 'lon': -119.6982},\n",
        "    {'name': 'Burbank-Glendale-Pasadena Airport', 'usw': 'USW00023152', 'lat': 34.2003, 'lon': -118.3552},\n",
        "    {'name': 'Oceanside Airport', 'usw': 'USW00023181', 'lat': 33.218, 'lon': -117.351}\n",
        "]\n",
        "\n",
        "# Square size in kilometers\n",
        "square_size_km = 80\n",
        "\n",
        "def create_weather_station_square(station_info, size_km):\n",
        "    \"\"\"Create a square polygon around a weather station\"\"\"\n",
        "    lat = station_info['lat']\n",
        "    lon = station_info['lon']\n",
        "\n",
        "    # Convert km to degrees (approximate: 1 degree ≈ 111 km)\n",
        "    size_deg = size_km / 111\n",
        "\n",
        "    # Create square coordinates\n",
        "    coords = [\n",
        "        [lon - size_deg/2, lat - size_deg/2],  # southwest\n",
        "        [lon + size_deg/2, lat - size_deg/2],  # southeast\n",
        "        [lon + size_deg/2, lat + size_deg/2],  # northeast\n",
        "        [lon - size_deg/2, lat + size_deg/2],  # northwest\n",
        "        [lon - size_deg/2, lat - size_deg/2]   # close polygon\n",
        "    ]\n",
        "\n",
        "    polygon = ee.Geometry.Polygon([coords])\n",
        "\n",
        "    # Intersect with California boundary to ensure we stay within state\n",
        "    return polygon.intersection(california)\n",
        "\n",
        "# Create weather station regions dictionary\n",
        "weather_regions = {}\n",
        "for station in weather_stations:\n",
        "    # Use USW ID as region identifier (clean version for naming)\n",
        "    region_key = f\"{station['usw']}_{station['name'].replace(' ', '_').replace('(', '').replace(')', '').replace('-', '_')}\"\n",
        "    weather_regions[region_key] = create_weather_station_square(station, square_size_km)\n",
        "\n",
        "# Load MODIS NDVI\n",
        "modis = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
        "    .select('NDVI') \\\n",
        "    .filterDate('2009-01-01', '2013-12-31') \\\n",
        "    .map(lambda img: img.multiply(0.0001).copyProperties(img, ['system:time_start']))\n",
        "\n",
        "# Extract NDVI for all weather station regions\n",
        "features = []\n",
        "for region_name, geometry in weather_regions.items():\n",
        "    def extract_ndvi(image):\n",
        "        stats = image.reduceRegion(\n",
        "            reducer=ee.Reducer.mean().combine(\n",
        "                ee.Reducer.stdDev().combine(\n",
        "                    ee.Reducer.min().combine(\n",
        "                        ee.Reducer.max(),\n",
        "                        sharedInputs=True\n",
        "                    ),\n",
        "                    sharedInputs=True\n",
        "                ),\n",
        "                sharedInputs=True\n",
        "            ),\n",
        "            geometry=geometry,\n",
        "            scale=250,\n",
        "            maxPixels=1e9\n",
        "        )\n",
        "\n",
        "        return ee.Feature(None, {\n",
        "            'region': region_name,\n",
        "            'usw_id': region_name.split('_')[0],  # Extract USW ID\n",
        "            'station_name': '_'.join(region_name.split('_')[1:]),  # Extract station name\n",
        "            'date': ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
        "            'ndvi_mean': stats.get('NDVI_mean'),\n",
        "            'ndvi_stddev': stats.get('NDVI_stdDev'),\n",
        "            'ndvi_min': stats.get('NDVI_min'),\n",
        "            'ndvi_max': stats.get('NDVI_max')\n",
        "        })\n",
        "\n",
        "    region_features = modis.map(extract_ndvi)\n",
        "    features.append(region_features)\n",
        "\n",
        "# Combine and export\n",
        "combined = ee.FeatureCollection(features).flatten()\n",
        "\n",
        "# Export task\n",
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=combined,\n",
        "    description='california_weather_station_ndvi',\n",
        "    folder='fire_prediction_project/raw_data/vegetation_modis',\n",
        "    fileNamePrefix='california_weather_station_ndvi',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "\n",
        "task.start()\n",
        "print(\"Export task started!\")\n",
        "print(\"Monitor progress at: https://code.earthengine.google.com/tasks\")\n",
        "\n",
        "# Print summary information\n",
        "print(f\"\\nProcessing {len(weather_stations)} weather stations:\")\n",
        "for station in weather_stations:\n",
        "    print(f\"  - {station['name']} ({station['usw']})\")\n",
        "print(f\"\\nSquare size: {square_size_km}km x {square_size_km}km\")\n",
        "print(f\"Total regions: {len(weather_regions)}\")\n"
      ],
      "metadata": {
        "id": "dUqMZW19zI3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_and_clean_ndvi():\n",
        "    \"\"\"Load, clean, and prepare NDVI data\"\"\"\n",
        "    # Load NDVI data\n",
        "    ndvi_path = '/content/drive/MyDrive/fire_prediction_project/raw_data/vegetation_modis/california_weather_station_ndvi.csv'\n",
        "    ndvi_df = pd.read_csv(ndvi_path)\n",
        "\n",
        "    # Clean data\n",
        "    ndvi_df['date'] = pd.to_datetime(ndvi_df['date'])\n",
        "    ndvi_df = ndvi_df.dropna(subset=['ndvi_mean'])\n",
        "    ndvi_df = ndvi_df[(ndvi_df['ndvi_mean'] >= -0.2) & (ndvi_df['ndvi_mean'] <= 1.0)]\n",
        "\n",
        "    # Add basic features\n",
        "    ndvi_df['vegetation_stress'] = 1 - ndvi_df['ndvi_mean'].clip(0, 1)\n",
        "    ndvi_df['month'] = ndvi_df['date'].dt.month\n",
        "    ndvi_df['day_of_year'] = ndvi_df['date'].dt.dayofyear\n",
        "\n",
        "    print(f\"Shape: {ndvi_df.shape}\")\n",
        "    print(f\"Date range: {ndvi_df['date'].min().date()} to {ndvi_df['date'].max().date()}\")\n",
        "    print(f\"Regions: {ndvi_df['region'].nunique()}\")\n",
        "\n",
        "    return ndvi_df\n",
        "\n",
        "# Load NDVI data\n",
        "ndvi_data = load_and_clean_ndvi()\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(ndvi_data.head())"
      ],
      "metadata": {
        "id": "1A7a388_ROQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"Set2\")\n",
        "\n",
        "def visualize_ndvi(ndvi_data):\n",
        "    \"\"\"Simple NDVI visualizations\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('NDVI Data Overview', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. NDVI by Region (Box plot)\n",
        "    axes[0,0].boxplot([ndvi_data[ndvi_data['region']==r]['ndvi_mean']\n",
        "                       for r in ndvi_data['region'].unique()],\n",
        "                      labels=ndvi_data['region'].unique())\n",
        "    axes[0,0].set_title('NDVI Distribution by Region')\n",
        "    axes[0,0].set_ylabel('NDVI')\n",
        "    axes[0,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 2. NDVI Time Series by Region\n",
        "    for region in ndvi_data['region'].unique():\n",
        "        region_data = ndvi_data[ndvi_data['region'] == region]\n",
        "        axes[0,1].plot(region_data['date'], region_data['ndvi_mean'],\n",
        "                       label=region, alpha=0.7)\n",
        "    axes[0,1].set_title('NDVI Over Time')\n",
        "    axes[0,1].set_ylabel('NDVI')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 3. Seasonal NDVI Pattern\n",
        "    monthly_ndvi = ndvi_data.groupby('month')['ndvi_mean'].mean()\n",
        "    axes[1,0].plot(monthly_ndvi.index, monthly_ndvi.values, 'o-', linewidth=2)\n",
        "    axes[1,0].set_title('Seasonal NDVI Pattern')\n",
        "    axes[1,0].set_xlabel('Month')\n",
        "    axes[1,0].set_ylabel('Average NDVI')\n",
        "    axes[1,0].set_xticks(range(1,13))\n",
        "\n",
        "    # 4. Vegetation Stress Distribution\n",
        "    axes[1,1].hist(ndvi_data['vegetation_stress'], bins=30, alpha=0.7, edgecolor='black')\n",
        "    axes[1,1].set_title('Vegetation Stress Distribution')\n",
        "    axes[1,1].set_xlabel('Vegetation Stress (1 - NDVI)')\n",
        "    axes[1,1].set_ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Summary stats\n",
        "    print(\"\\n📊 NDVI Summary by Region:\")\n",
        "    summary = ndvi_data.groupby('region')['ndvi_mean'].agg(['mean', 'std', 'min', 'max'])\n",
        "    print(summary.round(3))\n",
        "\n",
        "# Run visualization\n",
        "visualize_ndvi(ndvi_data)"
      ],
      "metadata": {
        "id": "CP6GnXvKSVgQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}