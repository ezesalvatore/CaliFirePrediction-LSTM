{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1HD4nFz-FdkWvr5uRNMnVaKBSEk3tEkhN",
      "authorship_tag": "ABX9TyODhS3UrRvWJbsFRWUstzPr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezesalvatore/CaliFirePrediction-LSTM/blob/main/CaliforniaWildfireRiskPredictionSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# California Wildfire Risk Prediction System\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "25LzU1YfcKTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Overview**\n",
        "  This machine learning project LSTM models with full-stack web development to create an wildfire prediction system for California.\n"
      ],
      "metadata": {
        "id": "VPqT-IDbCsDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Motivations**\n",
        "In recent years, California has experience massive wildfire seasons, with climate change only increasing the frequency and destructiveness of these fires. My mission is to prevent wildfires by predicting if they will happen. The prediction will give communities, firefighters, and other emergency services a head start."
      ],
      "metadata": {
        "id": "zX1j9IKJrTXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tech Stack**\n",
        "\n",
        "* **Datasets** of historical fire data\n",
        "* **LSTM models** built with TensorFlow/Keras trained in google collab\n",
        "* **Django** backends uses trained models with real-time API data\n",
        "* **React** displays interactive map interface with warnings"
      ],
      "metadata": {
        "id": "lp6Mk1n9rHtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Documentation**\n",
        "\n",
        "This documents information about the California Wildfire Risk Prediction System dataset being used. This inculdes its source, date range, variables, limitations, and citation information.\n"
      ],
      "metadata": {
        "id": "YNAQhNW7rW2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CAL FIRE Historic Wildland Fire Perimeters Dataset Documentation\n",
        "**Date Range** 1878- Present (Oldest and Cohesive on Cal Fire documentation <br>\n",
        "**Data Source** [California Department of Forestry and Fire Protection's Fire and Resource Assessment Program (FRAP)](https://www.fire.ca.gov/what-we-do/fire-resource-assessment-program/fire-perimeters)\n",
        "###**Limiation of Dataset**\n",
        "This is the most complete dataset for califorina history, but there are 483 fires that are totally missing from the CAL FIRE Redbook \"Large, Damaging Fires\"\n",
        "###**Data Collection of dataset**\n",
        "CAL Fire document fires that are: <br> >= 10 acres in timber <br> >= 50 acres in brush <br> >= 300 acres in grass <br>  >= 1 fatality <br> >= 3 residential building burned\n",
        "###**Variables used:**\n",
        "`ALARM_DATE`= Fire start date <br>\n",
        "`geometry` = Fire perimeter coordinates <br>\n",
        "`GIS_ACRES` = Fire size in acres\n",
        "###**Variables from Code**\n",
        "`fire_occurred` = Binary target variable (0 = no fire, 1 = fire happened)<br>\n",
        "`fire_size_acres` = Filtered fire size (>= 10 acres only)<br>\n"
      ],
      "metadata": {
        "id": "77hZvU96Qc36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NOAA National Centers for Environmental Information Dataset Documentation**<br>\n",
        "**Date Range:** January 1, 2009 - December 31, 2013 <br>\n",
        "**Data Source:** [NOAA GHCN-Daily dataset](https://www.ncei.noaa.gov/cdo-web/search?datasetid=GHCND)\n",
        "###**Station Location:**\n",
        "\n",
        "Redding Airport `USW00024257` <br>\n",
        "Marysville Airport `USW00093205`<br>\n",
        "Napa Airport `USW00093227`  <br> Santa Maria Airport `USW00023273`  <br> Watsonville Airport `USW00023277` <br>\n",
        "Merced Municipal Airport `USW00023257`<br> Bakersfield Airport `USW00023155`  <br>\n",
        " Santa Barbara 11W `USW00053152`<br>  Burbank-Glendale-Pasadena Airport `USW00023152` <br> Oceanside Airport `USW00053121`\n",
        "\n",
        "###**Variables Collected from Dataset:**\n",
        "`PRCP` = Precipitation (mm) <br>\n",
        "`TMAX`= Max Temp (Â°C) <br>\n",
        "`TMIN` = Min Temp (Â°C) <br>\n",
        "`AWND` = Average Wind Speed (m/s)\n",
        "\n",
        "###**Variables from Code**\n",
        "`temperature_range` = TMAX-TMIN <br>\n",
        "`days_since_rain` = Days with PRCP < 0.25 <br>\n",
        "`fire_season` = May - October period <br>\n",
        "`station_id` = Weather station <br>\n",
        "\n",
        "\n",
        "###**Citation**\n",
        "National Centers for Environmental Information, NOAA.(2025)\n"
      ],
      "metadata": {
        "id": "bneZLYKtH_8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Modis NDVI Dataset**\n",
        "**Date Range:** 2000-Present <br>\n",
        "**Data Source:** [Google Earth Engine - MODIS/061/MOD13Q1](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD13Q1)\n",
        "\n",
        "###**Regional Coverage**\n",
        "Since Califorina is made up with different regions with vastly differnt climate I separated the region my polygons will collect the data\n",
        "\n",
        "###**Data Collection Method**\n",
        "```python\n",
        "modis_ndvi = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
        "    .select('NDVI') \\\n",
        "    .filterDate('2009-01-01', '2013-12-31')\n",
        "```\n",
        "\n",
        "###**Variables from Dataset**\n",
        "`NDVI`= Raw MODIS NDVI band values (range: -1 to +1)\n",
        "\n",
        "###**Variables from Code**\n",
        "`ndvi_mean` = average NDVI for each fire region <br>\n",
        "`ndvi_stdev` = measure of NDVI variation<br>\n",
        "`region` = fire zone\n",
        "\n",
        "###**Citation**\n",
        "LP DAAC. (2021). MOD13Q1 MODIS/Terra Vegetation Indices 16-Day L3 Global 250m V061. NASA EOSDIS Land Processes DAAC."
      ],
      "metadata": {
        "id": "J2nwORqrNmZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Dataset Creation**"
      ],
      "metadata": {
        "id": "Fgs4BJeKqoBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/fire_prediction_project'\n",
        "folders = [\n",
        "    'raw_data/fires_calfire',\n",
        "    'raw_data/weather_ghcn',\n",
        "    'raw_data/vegetation_modis',\n",
        "]\n",
        "\n",
        "for folder in folders:\n",
        "    full_path = f'{base_path}/{folder}'\n",
        "    os.makedirs(full_path, exist_ok=True)\n",
        "    print(f\"Created: {folder}\")"
      ],
      "metadata": {
        "id": "AM4HmM5yq5Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if data exists\n",
        "\n",
        "print(os.listdir('/content/drive/MyDrive/fire_prediction_project/raw_data/fires_calfire'))\n",
        "print(os.listdir('/content/drive/MyDrive/fire_prediction_project/raw_data/weather_ghcn'))\n",
        "print(os.listdir('/content/drive/MyDrive/fire_prediction_project/raw_data/vegetation_modis'))\n"
      ],
      "metadata": {
        "id": "iWd5cZ7et4w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fire Perimeters Loading, Cleaning, Visulization data retrieved**"
      ],
      "metadata": {
        "id": "rEJzgBdEecnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "\n",
        "def load_fire_data():\n",
        "    \"\"\"\n",
        "    Loads CAL FIRE data and creates LSTM targets directly.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two pandas DataFrames:\n",
        "            - study_fires (pd.DataFrame or None): DataFrame of filtered fire incidents within the study period, or None if loading fails.\n",
        "            - daily_targets (pd.DataFrame or None): DataFrame of daily fire occurrence targets for LSTM, or None if loading fails.\n",
        "    \"\"\"\n",
        "    fire_folder = '/content/drive/MyDrive/fire_prediction_project/raw_data/fires_calfire'\n",
        "    print(f\"Looking for fire data in: {fire_folder}\")\n",
        "\n",
        "    if not os.path.exists(fire_folder):\n",
        "        print(\"Error: Fire folder not found!\")\n",
        "        return None, None\n",
        "\n",
        "    shp_files = [f for f in os.listdir(fire_folder) if f.endswith('.shp')]\n",
        "    if not shp_files:\n",
        "        print(\"Note: No fire shapefiles found.\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"Found {len(shp_files)} shapefile(s)\")\n",
        "    first_shp_file = f'{fire_folder}/{shp_files[0]}'\n",
        "\n",
        "    try:\n",
        "        fire_gdf = gpd.read_file(first_shp_file)\n",
        "        print(f\"Loaded {len(fire_gdf)} fire records\")\n",
        "        return process_fire_data(fire_gdf)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading shapefile: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def process_fire_data(fire_gdf):\n",
        "    \"\"\"\n",
        "    Process fire data and create LSTM targets.\n",
        "\n",
        "    Args:\n",
        "        fire_gdf (gpd.GeoDataFrame): GeoDataFrame containing the raw fire data.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two pandas DataFrames:\n",
        "            - study_fires (pd.DataFrame): DataFrame of processed and filtered fire incidents.\n",
        "            - daily_targets (pd.DataFrame): DataFrame of daily fire occurrence targets for LSTM.\n",
        "    \"\"\"\n",
        "    print(\"Processing fire data...\")\n",
        "\n",
        "    # Convert to WGS84 which is a common lat/longitude system\n",
        "    if fire_gdf.crs != 'EPSG:4326':\n",
        "        fire_gdf = fire_gdf.to_crs('EPSG:4326')\n",
        "\n",
        "    # Drop the geometry to get the center of the fire perimeter\n",
        "    fire_df = pd.DataFrame(fire_gdf.drop(columns='geometry'))\n",
        "\n",
        "    # Get the center of fire geometry\n",
        "    centroids = fire_gdf.geometry.centroid\n",
        "    fire_df['centroid_lat'] = centroids.y\n",
        "    fire_df['centroid_lon'] = centroids.x\n",
        "\n",
        "    # Define weather station coordinates\n",
        "    weather_stations = [\n",
        "        {'name': 'Redding Airport', 'usw_id': 'USW00024257', 'lat': 40.51, 'lon': -122.29},\n",
        "        {'name': 'Marysville Airport (Beale AFB)', 'usw_id': 'USW00093205', 'lat': 39.136089, 'lon': -121.436567},\n",
        "        {'name': 'Napa Airport', 'usw_id': 'USW00093227', 'lat': 38.213194, 'lon': -122.280694},\n",
        "        {'name': 'Santa Maria Airport', 'usw_id': 'USW00023273', 'lat': 34.8927, 'lon': -120.4545},\n",
        "        {'name': 'Watsonville Airport', 'usw_id': 'USW00023277', 'lat': 36.935, 'lon': -121.79},\n",
        "        {'name': 'Merced Municipal Airport', 'usw_id': 'USW00023257', 'lat': 37.28470, 'lon': -120.51400},\n",
        "        {'name': 'Bakersfield Airport', 'usw_id': 'USW00023155', 'lat': 35.3217, 'lon': -118.9910},\n",
        "        {'name': 'Santa Barbara 11W', 'usw_id': 'USW00053152', 'lat': 34.4208, 'lon': -119.6982},\n",
        "        {'name': 'Burbank-Glendale-Pasadena Airport', 'usw_id': 'USW00023152', 'lat': 34.2003, 'lon': -118.3552},\n",
        "        {'name': 'Oceanside Airport', 'usw_id': 'USW00023181', 'lat': 33.218, 'lon': -117.351}\n",
        "    ]\n",
        "\n",
        "    def find_nearest_weather_station(lat, lon):\n",
        "        \"\"\"\n",
        "        Find the nearest weather station to given coordinates.\n",
        "\n",
        "        Args:\n",
        "            lat (float): Latitude coordinate of the fire\n",
        "            lon (float): Longitude coordinate of the fire\n",
        "\n",
        "        Returns:\n",
        "            str: USW ID of the nearest weather station\n",
        "        \"\"\"\n",
        "        if pd.isna(lat) or pd.isna(lon):\n",
        "            return 'Unknown'\n",
        "\n",
        "        # Check if within California bounds (rough bounds)\n",
        "        if not (32.4 <= lat <= 42.2 and -124.6 <= lon <= -114.0):\n",
        "            return 'Unknown'\n",
        "\n",
        "        min_distance = float('inf')\n",
        "        nearest_station = 'Unknown'\n",
        "\n",
        "        for station in weather_stations:\n",
        "            # Calculate Euclidean distance (approximate since we're dealing with small distances)\n",
        "            distance = np.sqrt((lat - station['lat'])**2 + (lon - station['lon'])**2)\n",
        "\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                nearest_station = station['usw_id']\n",
        "\n",
        "        return nearest_station\n",
        "\n",
        "    # Assign each fire to its nearest weather station\n",
        "    fire_df['weather_station'] = fire_df.apply(\n",
        "        lambda row: find_nearest_weather_station(row['centroid_lat'], row['centroid_lon']),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Renaming columns to match expected format\n",
        "    column_mapping = {\n",
        "        'ALARM_DATE': 'fire_date',\n",
        "        'GIS_ACRES': 'fire_size_acres',\n",
        "        'YEAR_': 'year'\n",
        "    }\n",
        "    for old_name, new_name in column_mapping.items():\n",
        "        if old_name in fire_df.columns:\n",
        "            fire_df = fire_df.rename(columns={old_name: new_name})\n",
        "\n",
        "    # Process dates and filter\n",
        "    if 'fire_date' not in fire_df.columns:\n",
        "        print(\"Warning: 'fire_date' column not found.\")\n",
        "        return None, None\n",
        "\n",
        "    fire_df['fire_date'] = pd.to_datetime(fire_df['fire_date'], errors='coerce')\n",
        "    fire_df = fire_df.dropna(subset=['fire_date'])\n",
        "\n",
        "    # Filter to study period and significant fires\n",
        "    study_fires = fire_df[\n",
        "        (fire_df['fire_date'] >= '2009-01-01') &\n",
        "        (fire_df['fire_date'] <= '2013-12-31')\n",
        "    ].copy()\n",
        "\n",
        "    if 'fire_size_acres' in study_fires.columns:\n",
        "        study_fires = study_fires[study_fires['fire_size_acres'] >= 10]\n",
        "\n",
        "    print(f\"Study period fires: {len(study_fires)} (2009-2013)\")\n",
        "\n",
        "    # Print distribution by weather station\n",
        "    print(\"\\nFire distribution by weather station:\")\n",
        "    station_counts = study_fires['weather_station'].value_counts()\n",
        "    for station_id, count in station_counts.items():\n",
        "        station_name = next((s['name'] for s in weather_stations if s['usw_id'] == station_id), station_id)\n",
        "        print(f\"  {station_name} ({station_id}): {count} fires\")\n",
        "\n",
        "    # Create LSTM targets\n",
        "    daily_targets = create_daily_fire_targets(study_fires)\n",
        "\n",
        "    return study_fires, daily_targets\n",
        "\n",
        "def create_daily_fire_targets(fire_df):\n",
        "    \"\"\"\n",
        "    Creates 5-day fire prediction targets for LSTM training.\n",
        "\n",
        "    Args:\n",
        "        fire_df (pd.DataFrame): DataFrame of fire incidents with 'fire_date' and 'weather_station' columns.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with daily 5-day fire prediction targets.\n",
        "    \"\"\"\n",
        "    print(\"Creating 5-day fire prediction targets...\")\n",
        "\n",
        "    if 'fire_date' not in fire_df.columns or 'weather_station' not in fire_df.columns:\n",
        "        print(\"Warning: Missing required columns for targets.\")\n",
        "        return None\n",
        "\n",
        "    # Create date range - end 5 days early to allow for 5-day prediction window\n",
        "    date_range = pd.date_range('2009-01-01', '2013-12-26', freq='D')  # Dec 26 instead of Dec 31\n",
        "    stations = fire_df['weather_station'].unique()\n",
        "    stations = [s for s in stations if s != 'Unknown']\n",
        "\n",
        "    # Build daily targets\n",
        "    daily_targets = []\n",
        "    for date in date_range:\n",
        "        for station in stations:\n",
        "            # Look for fires in the next 5 days (tomorrow through day 5)\n",
        "            window_start = date + pd.Timedelta(days=1)\n",
        "            window_end = date + pd.Timedelta(days=5)\n",
        "\n",
        "            fires_in_window = fire_df[\n",
        "                (fire_df['fire_date'] >= window_start) &\n",
        "                (fire_df['fire_date'] <= window_end) &\n",
        "                (fire_df['weather_station'] == station)\n",
        "            ]\n",
        "\n",
        "            daily_targets.append({\n",
        "                'date': date,\n",
        "                'weather_station': station,\n",
        "                'fire_within_5_days': 1 if len(fires_in_window) > 0 else 0\n",
        "            })\n",
        "\n",
        "    targets_df = pd.DataFrame(daily_targets)\n",
        "\n",
        "    # Print statistics\n",
        "    positive_rate = targets_df['fire_within_5_days'].mean() * 100\n",
        "    print(f\"Created {len(targets_df)} daily target records\")\n",
        "    print(f\"5-day fire prediction rate: {positive_rate:.1f}%\")\n",
        "\n",
        "    return targets_df\n",
        "\n",
        "# Load and process fire data\n",
        "print(\"Loading fire data...\")\n",
        "fire_data, fire_targets = load_fire_data()\n",
        "\n",
        "print(f\"\\nFire data shape: {fire_data.shape if fire_data is not None else 'None'}\")\n",
        "print(f\"LSTM targets shape: {fire_targets.shape if fire_targets is not None else 'None'}\")"
      ],
      "metadata": {
        "id": "cLzqSazDekyD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def visualize_fire_data(fire_data, fire_targets):\n",
        "    \"\"\"Simple fire data visualizations\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Fire Data Overview', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Fire occurrences by region\n",
        "    region_fires = fire_data['weather_station'].value_counts()\n",
        "    axes[0,0].bar(region_fires.index, region_fires.values)\n",
        "    axes[0,0].set_title('Total Fires by Region (2009-2013)')\n",
        "    axes[0,0].set_ylabel('Number of Fires')\n",
        "    axes[0,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 2. Fire size distribution\n",
        "    axes[0,1].hist(fire_data['fire_size_acres'], bins=50, alpha=0.7, edgecolor='black')\n",
        "    axes[0,1].set_title('Fire Size Distribution')\n",
        "    axes[0,1].set_xlabel('Fire Size (acres)')\n",
        "    axes[0,1].set_ylabel('Frequency')\n",
        "    axes[0,1].set_yscale('log')\n",
        "\n",
        "    # 3. Monthly fire occurrence rate\n",
        "    monthly_fire_rate = fire_targets.groupby(fire_targets['date'].dt.month)['fire_occurred'].mean() * 100\n",
        "    axes[1,0].plot(monthly_fire_rate.index, monthly_fire_rate.values, 'o-', linewidth=2)\n",
        "    axes[1,0].set_title('Monthly Fire Occurrence Rate')\n",
        "    axes[1,0].set_xlabel('Month')\n",
        "    axes[1,0].set_ylabel('Fire Rate (%)')\n",
        "    axes[1,0].set_xticks(range(1,13))\n",
        "\n",
        "    # 4. Fire occurrence by region (daily targets)\n",
        "    region_fire_rates = fire_targets.groupby('weather_station')['fire_occurred'].mean() * 100\n",
        "    axes[1,1].bar(region_fire_rates.index, region_fire_rates.values)\n",
        "    axes[1,1].set_title('Fire Occurrence Rate by Region')\n",
        "    axes[1,1].set_ylabel('Fire Rate (%)')\n",
        "    axes[1,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Summary stats\n",
        "    print(\"\\nðŸ”¥ Fire Data Summary:\")\n",
        "    print(f\"Total fires: {len(fire_data)}\")\n",
        "    print(f\"Date range: {fire_data['fire_date'].min().date()} to {fire_data['fire_date'].max().date()}\")\n",
        "    print(f\"Average fire size: {fire_data['fire_size_acres'].mean():.0f} acres\")\n",
        "    print(f\"Overall fire rate: {fire_targets['fire_occurred'].mean()*100:.1f}%\")\n",
        "\n",
        "# Run visualization\n",
        "if fire_data is not None and fire_targets is not None:\n",
        "    visualize_fire_data(fire_data, fire_targets)\n",
        "else:\n",
        "    print(\"No fire data to visualize\")"
      ],
      "metadata": {
        "id": "7DsU1YzXBfVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NOAA load, clean, visulization, and retrival**"
      ],
      "metadata": {
        "id": "SfzFnwjFVeBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_weather_data():\n",
        "    \"\"\"\n",
        "    Load and process weather data from NOAA GHCN-Daily dataset for fire prediction.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Processed weather data with engineered features, or None if loading fails.\n",
        "    \"\"\"\n",
        "    weather_path = '/content/drive/MyDrive/fire_prediction_project/raw_data/weather_ghcn/4030557.csv'\n",
        "\n",
        "    print(f\"Loading weather data from: {weather_path}\")\n",
        "\n",
        "    if not os.path.exists(weather_path):\n",
        "        print(\"Error: Weather file not found!\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Load the weather data\n",
        "        weather_df = pd.read_csv(weather_path)\n",
        "        print(f\"Loaded {len(weather_df)} weather records\")\n",
        "\n",
        "        # Process the weather data\n",
        "        processed_weather = process_weather_data(weather_df)\n",
        "\n",
        "        return processed_weather\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading weather data: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_weather_data(weather_df):\n",
        "    \"\"\"\n",
        "    Process raw weather data and create engineered features.\n",
        "\n",
        "    Args:\n",
        "        weather_df (pd.DataFrame): Raw weather data from NOAA\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Processed weather data with engineered features\n",
        "    \"\"\"\n",
        "    print(\"Processing weather data...\")\n",
        "\n",
        "    # Convert date column\n",
        "    weather_df['DATE'] = pd.to_datetime(weather_df['DATE'])\n",
        "\n",
        "    # Filter to study period\n",
        "    weather_df = weather_df[\n",
        "        (weather_df['DATE'] >= '2009-01-01') &\n",
        "        (weather_df['DATE'] <= '2013-12-31')\n",
        "    ].copy()\n",
        "\n",
        "    # Rename columns for consistency\n",
        "    weather_df = weather_df.rename(columns={\n",
        "        'DATE': 'date',\n",
        "        'STATION': 'weather_station'\n",
        "    })\n",
        "\n",
        "    # Convert temperature from tenths of degrees C to degrees C\n",
        "    if 'TMAX' in weather_df.columns:\n",
        "        weather_df['TMAX'] = weather_df['TMAX'] / 10.0\n",
        "    if 'TMIN' in weather_df.columns:\n",
        "        weather_df['TMIN'] = weather_df['TMIN'] / 10.0\n",
        "\n",
        "    # Convert precipitation from tenths of mm to mm\n",
        "    if 'PRCP' in weather_df.columns:\n",
        "        weather_df['PRCP'] = weather_df['PRCP'] / 10.0\n",
        "\n",
        "    # Convert wind speed from tenths of m/s to m/s\n",
        "    if 'AWND' in weather_df.columns:\n",
        "        weather_df['AWND'] = weather_df['AWND'] / 10.0\n",
        "\n",
        "    # Create engineered features\n",
        "    weather_df = create_weather_features(weather_df)\n",
        "\n",
        "    print(f\"Processed weather data: {len(weather_df)} records\")\n",
        "    print(f\"Date range: {weather_df['date'].min().date()} to {weather_df['date'].max().date()}\")\n",
        "    print(f\"Weather stations: {weather_df['weather_station'].nunique()}\")\n",
        "\n",
        "    return weather_df\n",
        "\n",
        "def create_weather_features(weather_df):\n",
        "    \"\"\"\n",
        "    Create engineered weather features for fire prediction.\n",
        "\n",
        "    Args:\n",
        "        weather_df (pd.DataFrame): Basic weather data\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Weather data with engineered features\n",
        "    \"\"\"\n",
        "    print(\"Creating weather features...\")\n",
        "\n",
        "    # Temperature range\n",
        "    if 'TMAX' in weather_df.columns and 'TMIN' in weather_df.columns:\n",
        "        weather_df['temperature_range'] = weather_df['TMAX'] - weather_df['TMIN']\n",
        "\n",
        "    # Fire season indicator (May - October)\n",
        "    weather_df['fire_season'] = weather_df['date'].dt.month.isin([5, 6, 7, 8, 9, 10]).astype(int)\n",
        "\n",
        "    # Days since rain (calculated per weather station)\n",
        "    weather_df = weather_df.sort_values(['weather_station', 'date'])\n",
        "\n",
        "    def calculate_days_since_rain(group):\n",
        "        \"\"\"Calculate days since last significant rain (>= 0.25mm) for each station\"\"\"\n",
        "        group = group.copy()\n",
        "        group['days_since_rain'] = 0\n",
        "\n",
        "        if 'PRCP' in group.columns:\n",
        "            last_rain_day = 0\n",
        "            for i, row in group.iterrows():\n",
        "                if pd.notna(row['PRCP']) and row['PRCP'] >= 0.25:\n",
        "                    last_rain_day = 0\n",
        "                else:\n",
        "                    last_rain_day += 1\n",
        "                group.loc[i, 'days_since_rain'] = last_rain_day\n",
        "\n",
        "        return group\n",
        "\n",
        "    # Apply days since rain calculation by weather station\n",
        "    weather_df = weather_df.groupby('weather_station').apply(calculate_days_since_rain).reset_index(drop=True)\n",
        "\n",
        "    # Fill missing values\n",
        "    weather_df['PRCP'] = weather_df['PRCP'].fillna(0)\n",
        "    weather_df['AWND'] = weather_df['AWND'].fillna(weather_df['AWND'].mean())\n",
        "\n",
        "    # Select final columns\n",
        "    feature_columns = [\n",
        "        'date', 'weather_station', 'PRCP', 'TMAX', 'TMIN', 'AWND',\n",
        "        'temperature_range', 'days_since_rain', 'fire_season'\n",
        "    ]\n",
        "\n",
        "    # Only keep columns that exist\n",
        "    available_columns = [col for col in feature_columns if col in weather_df.columns]\n",
        "    weather_df = weather_df[available_columns]\n",
        "\n",
        "    print(f\"Weather features created: {list(weather_df.columns)}\")\n",
        "\n",
        "    # Print basic statistics\n",
        "    print(\"\\nWeather data summary:\")\n",
        "    print(f\"  Average TMAX: {weather_df['TMAX'].mean():.1f}Â°C\")\n",
        "    print(f\"  Average TMIN: {weather_df['TMIN'].mean():.1f}Â°C\")\n",
        "    print(f\"  Average PRCP: {weather_df['PRCP'].mean():.1f}mm\")\n",
        "    print(f\"  Fire season days: {weather_df['fire_season'].sum()}\")\n",
        "    print(f\"  Max days since rain: {weather_df['days_since_rain'].max()}\")\n",
        "\n",
        "    return weather_df\n",
        "\n",
        "# Load weather data\n",
        "print(\"Loading weather data...\")\n",
        "weather_data = load_weather_data()\n",
        "\n",
        "if weather_data is not None:\n",
        "    print(f\"\\nWeather data shape: {weather_data.shape}\")\n",
        "    print(\"\\nSample weather data:\")\n",
        "    print(weather_data.head())\n",
        "else:\n",
        "    print(\"Failed to load weather data.\")"
      ],
      "metadata": {
        "id": "SYIu4uVMVzNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Google Earth Engine Code for NDVI Data Retrieval**"
      ],
      "metadata": {
        "id": "qCN1M2N-IvCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "# Initialize GEE\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='fire-prediction-ee-salvatore')\n",
        "\n",
        "# Define California state boundary for intersection\n",
        "california = ee.FeatureCollection(\"TIGER/2018/States\") \\\n",
        "    .filter(ee.Filter.eq('STUSPS', 'CA')) \\\n",
        "    .geometry()\n",
        "\n",
        "# Weather station locations (from your JavaScript code)\n",
        "weather_stations = [\n",
        "    {'name': 'Redding Airport', 'usw': 'USW00024257', 'lat': 40.51, 'lon': -122.29},\n",
        "    {'name': 'Marysville Airport (Beale AFB)', 'usw': 'USW00093205', 'lat': 39.136089, 'lon': -121.436567},\n",
        "    {'name': 'Napa Airport', 'usw': 'USW00093227', 'lat': 38.213194, 'lon': -122.280694},\n",
        "    {'name': 'Santa Maria Airport', 'usw': 'USW00023273', 'lat': 34.8927, 'lon': -120.4545},\n",
        "    {'name': 'Watsonville Airport', 'usw': 'USW00023277', 'lat': 36.935, 'lon': -121.79},\n",
        "    {'name': 'Merced Municipal Airport', 'usw': 'USW00023257', 'lat': 37.28470, 'lon': -120.51400},\n",
        "    {'name': 'Bakersfield Airport', 'usw': 'USW00023155', 'lat': 35.3217, 'lon': -118.9910},\n",
        "    {'name': 'Santa Barbara 11W', 'usw': 'USW00053152', 'lat': 34.4208, 'lon': -119.6982},\n",
        "    {'name': 'Burbank-Glendale-Pasadena Airport', 'usw': 'USW00023152', 'lat': 34.2003, 'lon': -118.3552},\n",
        "    {'name': 'Oceanside Airport', 'usw': 'USW00023181', 'lat': 33.218, 'lon': -117.351}\n",
        "]\n",
        "\n",
        "# Square size in kilometers (80km x 80km as in your JavaScript code)\n",
        "square_size_km = 80\n",
        "\n",
        "def create_weather_station_square(station_info, size_km):\n",
        "    \"\"\"Create a square polygon around a weather station\"\"\"\n",
        "    lat = station_info['lat']\n",
        "    lon = station_info['lon']\n",
        "\n",
        "    # Convert km to degrees (approximate: 1 degree â‰ˆ 111 km)\n",
        "    size_deg = size_km / 111\n",
        "\n",
        "    # Create square coordinates\n",
        "    coords = [\n",
        "        [lon - size_deg/2, lat - size_deg/2],  # southwest\n",
        "        [lon + size_deg/2, lat - size_deg/2],  # southeast\n",
        "        [lon + size_deg/2, lat + size_deg/2],  # northeast\n",
        "        [lon - size_deg/2, lat + size_deg/2],  # northwest\n",
        "        [lon - size_deg/2, lat - size_deg/2]   # close polygon\n",
        "    ]\n",
        "\n",
        "    polygon = ee.Geometry.Polygon([coords])\n",
        "\n",
        "    # Intersect with California boundary to ensure we stay within state\n",
        "    return polygon.intersection(california)\n",
        "\n",
        "# Create weather station regions dictionary\n",
        "weather_regions = {}\n",
        "for station in weather_stations:\n",
        "    # Use USW ID as region identifier (clean version for naming)\n",
        "    region_key = f\"{station['usw']}_{station['name'].replace(' ', '_').replace('(', '').replace(')', '')}\"\n",
        "    weather_regions[region_key] = create_weather_station_square(station, square_size_km)\n",
        "\n",
        "# Load MODIS NDVI\n",
        "modis = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
        "    .select('NDVI') \\\n",
        "    .filterDate('2009-01-01', '2013-12-31') \\\n",
        "    .map(lambda img: img.multiply(0.0001).copyProperties(img, ['system:time_start']))\n",
        "\n",
        "# Extract NDVI for all weather station regions\n",
        "features = []\n",
        "for region_name, geometry in weather_regions.items():\n",
        "    def extract_ndvi(image):\n",
        "        stats = image.reduceRegion(\n",
        "            reducer=ee.Reducer.mean().combine(\n",
        "                ee.Reducer.stdDev().combine(\n",
        "                    ee.Reducer.min().combine(\n",
        "                        ee.Reducer.max(),\n",
        "                        sharedInputs=True\n",
        "                    ),\n",
        "                    sharedInputs=True\n",
        "                ),\n",
        "                sharedInputs=True\n",
        "            ),\n",
        "            geometry=geometry,\n",
        "            scale=250,\n",
        "            maxPixels=1e9\n",
        "        )\n",
        "\n",
        "        return ee.Feature(None, {\n",
        "            'region': region_name,\n",
        "            'usw_id': region_name.split('_')[0],  # Extract USW ID\n",
        "            'station_name': '_'.join(region_name.split('_')[1:]),  # Extract station name\n",
        "            'date': ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
        "            'ndvi_mean': stats.get('NDVI_mean'),\n",
        "            'ndvi_stddev': stats.get('NDVI_stdDev'),\n",
        "            'ndvi_min': stats.get('NDVI_min'),\n",
        "            'ndvi_max': stats.get('NDVI_max')\n",
        "        })\n",
        "\n",
        "    region_features = modis.map(extract_ndvi)\n",
        "    features.append(region_features)\n",
        "\n",
        "# Combine and export\n",
        "combined = ee.FeatureCollection(features).flatten()\n",
        "\n",
        "# Export task\n",
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=combined,\n",
        "    description='california_weather_station_ndvi_80km',\n",
        "    folder='fire_prediction_project/raw_data/vegetation_modis',\n",
        "    fileNamePrefix='california_weather_station_ndvi_80km',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "\n",
        "task.start()\n",
        "print(\"Export task started!\")\n",
        "print(\"Monitor progress at: https://code.earthengine.google.com/tasks\")\n",
        "\n",
        "# Print summary information\n",
        "print(f\"\\nProcessing {len(weather_stations)} weather stations:\")\n",
        "for station in weather_stations:\n",
        "    print(f\"  - {station['name']} ({station['usw']})\")\n",
        "print(f\"\\nSquare size: {square_size_km}km x {square_size_km}km\")\n",
        "print(f\"Total regions: {len(weather_regions)}\")"
      ],
      "metadata": {
        "id": "dUqMZW19zI3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_and_clean_ndvi():\n",
        "    \"\"\"Load, clean, and prepare NDVI data\"\"\"\n",
        "    # Load NDVI data\n",
        "    ndvi_path = '/content/drive/MyDrive/fire_prediction_project/raw_data/vegetation_modis/california_weather_station_ndvi_80km.csv'\n",
        "    ndvi_df = pd.read_csv(ndvi_path)\n",
        "\n",
        "    # Clean data\n",
        "    ndvi_df['date'] = pd.to_datetime(ndvi_df['date'])\n",
        "    ndvi_df = ndvi_df.dropna(subset=['ndvi_mean'])\n",
        "    ndvi_df = ndvi_df[(ndvi_df['ndvi_mean'] >= -0.2) & (ndvi_df['ndvi_mean'] <= 1.0)]\n",
        "\n",
        "    # Add basic features\n",
        "    ndvi_df['vegetation_stress'] = 1 - ndvi_df['ndvi_mean'].clip(0, 1)\n",
        "    ndvi_df['month'] = ndvi_df['date'].dt.month\n",
        "    ndvi_df['day_of_year'] = ndvi_df['date'].dt.dayofyear\n",
        "\n",
        "    print(f\"Shape: {ndvi_df.shape}\")\n",
        "    print(f\"Date range: {ndvi_df['date'].min().date()} to {ndvi_df['date'].max().date()}\")\n",
        "    print(f\"Regions: {ndvi_df['region'].nunique()}\")\n",
        "\n",
        "    return ndvi_df\n",
        "\n",
        "# Load NDVI data\n",
        "ndvi_data = load_and_clean_ndvi()\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(ndvi_data.head())"
      ],
      "metadata": {
        "id": "1A7a388_ROQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"Set2\")\n",
        "\n",
        "def visualize_ndvi(ndvi_data):\n",
        "    \"\"\"Simple NDVI visualizations\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('NDVI Data Overview', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. NDVI by Region (Box plot)\n",
        "    axes[0,0].boxplot([ndvi_data[ndvi_data['region']==r]['ndvi_mean']\n",
        "                       for r in ndvi_data['region'].unique()],\n",
        "                      labels=ndvi_data['region'].unique())\n",
        "    axes[0,0].set_title('NDVI Distribution by Region')\n",
        "    axes[0,0].set_ylabel('NDVI')\n",
        "    axes[0,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 2. NDVI Time Series by Region\n",
        "    for region in ndvi_data['region'].unique():\n",
        "        region_data = ndvi_data[ndvi_data['region'] == region]\n",
        "        axes[0,1].plot(region_data['date'], region_data['ndvi_mean'],\n",
        "                       label=region, alpha=0.7)\n",
        "    axes[0,1].set_title('NDVI Over Time')\n",
        "    axes[0,1].set_ylabel('NDVI')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 3. Seasonal NDVI Pattern\n",
        "    monthly_ndvi = ndvi_data.groupby('month')['ndvi_mean'].mean()\n",
        "    axes[1,0].plot(monthly_ndvi.index, monthly_ndvi.values, 'o-', linewidth=2)\n",
        "    axes[1,0].set_title('Seasonal NDVI Pattern')\n",
        "    axes[1,0].set_xlabel('Month')\n",
        "    axes[1,0].set_ylabel('Average NDVI')\n",
        "    axes[1,0].set_xticks(range(1,13))\n",
        "\n",
        "    # 4. Vegetation Stress Distribution\n",
        "    axes[1,1].hist(ndvi_data['vegetation_stress'], bins=30, alpha=0.7, edgecolor='black')\n",
        "    axes[1,1].set_title('Vegetation Stress Distribution')\n",
        "    axes[1,1].set_xlabel('Vegetation Stress (1 - NDVI)')\n",
        "    axes[1,1].set_ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Summary stats\n",
        "    print(\"\\nðŸ“Š NDVI Summary by Region:\")\n",
        "    summary = ndvi_data.groupby('region')['ndvi_mean'].agg(['mean', 'std', 'min', 'max'])\n",
        "    print(summary.round(3))\n",
        "\n",
        "# Run visualization\n",
        "visualize_ndvi(ndvi_data)"
      ],
      "metadata": {
        "id": "CP6GnXvKSVgQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}